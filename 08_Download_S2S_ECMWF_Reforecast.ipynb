{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29cb85-5e23-4d30-80ca-8daa442f5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Basic function definition for S2S // No modification required ########################################333333\n",
    "parameter_num = {'mn2t6': 122,'mx2t6': 121,'tp': 228228,'10u': 165,'10v': 166,'ssr':176,'2d':168,'2t': 167}\n",
    "institutions= {'ecmf': 'ECMWF','babj': 'CMA', 'kwbc': 'NCEP'}\n",
    "num=\"1/2/3/4/5/6/7/8/9/10\" # Prediction member numbers\n",
    "# The forecast interval for mn2t6 (minimum 2m temperature 6-hourly), mx2t6 (maximum 2m temperature 6-hourly), and tp (total precipitation) is 6 hours, missing the 00:00 of day 0. \n",
    "# Therefore, forecast 47*4-1=187 fields in the future. # Verify that 06:00, 12:00, and 18:00 of 47 days are not missing\n",
    "step1 = \"\"\"6/12/18/24/30/36/42/48/54/60/66/72/78/84/90/96/102/108/114/120/126/132/138/144/150/156/162/168\n",
    "/174/180/186/192/198/204/210/216/222/228/234/240/246/252/258/264/270/276/282/288/294/300/306/312\n",
    "/318/324/330/336/342/348/354/360/366/372/378/384/390/396/402/408/414/420/426/432/438/444/450/456\n",
    "/462/468/474/480/486/492/498/504/510/516/522/528/534/540/546/552/558/564/570/576/582/588/594/600\n",
    "/606/612/618/624/630/636/642/648/654/660/666/672/678/684/690/696/702/708/714/720/726/732/738/744\n",
    "/750/756/762/768/774/780/786/792/798/804/810/816/822/828/834/840/846/852/858/864/870/876/882/888\n",
    "/894/900/906/912/918/924/930/936/942/948/954/960/966/972/978/984/990/996/1002/1008/1014/1020/1026\n",
    "/1032/1038/1044/1050/1056/1062/1068/1074/1080/1086/1092/1098/1104\"\"\"\n",
    "\n",
    "# Interpolation required / Not required\n",
    "# The forecast interval for tp is 6 hours, cumulative precipitation every 6 hours starting from the 0th time step, but only need to download 00:00 daily\n",
    "# The forecast interval for ssr (surface solar radiation) is 24 hours\n",
    "step2=\"\"\"0/24/48/72/96/120/144/168/192/216/240/264/288/312/336/360/384/408/432/456/480/504/528/552/576\n",
    "/600/624/648/672/696/720/744/768/792/816/840/864/888/912/936/960/984/1008/1032/1056/1080/1104\"\"\"\n",
    "\n",
    "# No interpolation required\n",
    "# After 2020-01-02, the forecasts for 10u (10m zonal wind) and 10v (10m meridional wind) were changed to 6-hourly, but only need to download 00:00 daily\n",
    "step3=\"\"\"24/48/72/96/120/144/168/192/216/240/264/288/312/336/360/384/408/432/456/480/504/528/552/576\n",
    "/600/624/648/672/696/720/744/768/792/816/840/864/888/912/936/960/984/1008/1032/1056/1080/1104\"\"\"\n",
    "\n",
    "\n",
    "# Daily averaged\n",
    "# 2d (2 metre dewpoint temperature) and 2t (2 metre temperature) are daily aggregated\n",
    "step4 = \"\"\"0-24/24-48/48-72/72-96/96-120/120-144/144-168/168-192/192-216/216-240/240-264/264-288/288-312/312-336\n",
    "/336-360/360-384/384-408/408-432/432-456/456-480/480-504/504-528/528-552/552-576/576-600\n",
    "/600-624/624-648/648-672/672-696/696-720/720-744/744-768/768-792/792-816/816-840/840-864/864-888\n",
    "/888-912/912-936/936-960/960-984/984-1008/1008-1032/1032-1056/1056-1080/1080-1104\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta,date\n",
    "root_directory = os.getcwd()[0:3]\n",
    "sys.path.append(root_directory+'SCI\\\\SCI9_1\\\\01_code')\n",
    "sys.path.append(r'C:\\ProgramData\\anaconda3\\Lib\\site-packages') \n",
    "sys.path.append(r'C:\\Users\\DELL\\.conda\\envs\\myenv\\Lib\\site-packages') \n",
    "#sys.path.append(r'C:\\Users\\DELL\\.conda\\envs\\rasterio_env\\Lib\\site-packages') \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from functions import prepare_and_model_data,extract_selected_variables\n",
    "from functions import calculate_region_bounds,filter_dates,retrieve_mx2t6_mn2t6,retrieve_tp_10_u_10v_ssr,retrieve_2d_2t\n",
    "from datetime import datetime, timedelta,date\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "root_directory = os.getcwd()[0:3]\n",
    "\n",
    "# Variables that need modification\n",
    "crop = '02_Wheat';countryID ='06_India';country =countryID.split('_')[1]\n",
    "region ='I';shp_name = 'Indiagee_up_load_winter.shp'\n",
    "inpath_dates_other = root_directory + '\\\\SCI\\\\SCI9_1\\\\02_data\\\\'+crop+'\\\\'+countryID+'\\\\'+'01_data'+'\\\\'+'07_Information'\n",
    "other_infornamtion = pd.read_csv(os.path.join(inpath_dates_other,'information.txt'), sep=' ', header=None)\n",
    "startyear,endyear,shp_name = other_infornamtion.iloc[0,0],other_infornamtion.iloc[0,1],other_infornamtion.iloc[0,2]\n",
    "\n",
    "regions = ['I']\n",
    "Forecastyears = {'I': endyear}\n",
    "\n",
    "\n",
    "# Directory change\n",
    "inputpath_base = root_directory + '\\\\SCI\\\\SCI9_1\\\\02_data\\\\'+crop+'\\\\'+countryID+'\\\\'\n",
    "yield_type = 'actual_yield';\n",
    "\n",
    "############## Regional settings #############################################\n",
    "shp_all = os.path.join(inputpath_base,'01_data','02_shp',shp_name)\n",
    "gdf_all = gpd.read_file(shp_all)\n",
    "\n",
    "\n",
    "\n",
    "# Read and extract basic growing season information\n",
    "inpath_dates = os.path.join(inputpath_base, '01_data','05_buildmodel', '02_extractdates','gs_three_periods.txt')\n",
    "gs_infornamtion = pd.read_csv(inpath_dates, delim_whitespace=True, header=None)\n",
    "gs_infornamtion.columns = ['start_point', 'peak', 'harvest_point', 'VI_select2','regionID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9c09a-e093-4432-963d-65491c8fb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also modified to reduce rolling weeks - only need to download the current week's data\n",
    "def find_weeks(inputpath_base, forecastDataList):\n",
    "    \n",
    "    # Read the corresponding weeks\n",
    "    file_path = os.path.join(inputpath_base, '02_S2S', '01_dataori', 'ECMWF', 'CommonYear_Week.txt')\n",
    "    with open(file_path, 'r') as file:\n",
    "        week_dates = [line.strip() for line in file.readlines()]\n",
    "    result = []\n",
    "    \n",
    "    # Iterate through each date in forecastDataList\n",
    "    for date in forecastDataList:\n",
    "        # Iterate through week_dates to find the week corresponding to the date\n",
    "        for i in range(len(week_dates) - 1):\n",
    "            # Check if the date is within the current date range (inclusive of lower bound, exclusive of upper bound)\n",
    "            if week_dates[i] <= date < week_dates[i + 1]:\n",
    "                result.append((date, i + 1))  # Week 1 corresponds to index 0, so week number is i + 1\n",
    "                break\n",
    "        # Handle dates beyond the last date range (i.e., the range for Week 46)\n",
    "        else:\n",
    "            if date >= week_dates[-1]:\n",
    "                result.append((date, len(week_dates)))  # Last week: Week 46\n",
    "    result = {date: week for date, week in result}\n",
    "    return result\n",
    "\n",
    "# Download S2S dataset from ECMWF\n",
    "\n",
    "# Also modified to reduce rolling weeks - only need to download the current week's data\n",
    "origen = \"ecmf\"\n",
    "institution = 'ECMWF'  # Data source\n",
    "hyear = '2021'\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    # Filter the shapefile for the sub-region and get spatial extent\n",
    "    if 'region' not in gdf_all.columns:\n",
    "        gdf_all['region'] = 'I'\n",
    "        gdf_all_sel = gdf_all\n",
    "    else:\n",
    "        gdf_all_sel = gdf_all  # [gdf_all['region']==region] # [ToDo] Verify if there are sub-regions\n",
    "    region_limits = calculate_region_bounds(gdf_all_sel, offset=2)\n",
    "    \n",
    "    # Filter backward dates\n",
    "    start_point, peak, harvest_point, VI_select2, region = gs_infornamtion[gs_infornamtion['regionID'] == region].iloc[0]\n",
    "    # Note: Aggregation to 8-day periods is backward-looking. For example, \"01-01\" refers to aggregated indicators from 01-01 to 01-08\n",
    "\n",
    "    ############## Filter backward dates #######################################################\n",
    "    if start_point < harvest_point:  # Growing season in the same year\n",
    "        weeks = len(list(range(start_point, harvest_point)))\n",
    "    else:\n",
    "        weeks = len(list(range(1, harvest_point))) + len(list(range(start_point, 46 + 1)))\n",
    "    \n",
    "    filtered_dates = filter_dates(inputpath_base, hyear, harvest_point, institution, weeks)\n",
    "    # weeks represents the number of 8-day weeks in the growing season\n",
    "\n",
    "    ########################### Simplify forecast data download #####################\n",
    "    ######## If there are 2-3 downloads per week, select only one\n",
    "    new_dates = [date[5:] for date in filtered_dates]  # Extract \"mm-dd\" from \"yyyy-mm-dd\" format\n",
    "    dataweeks = find_weeks(inputpath_base, new_dates)\n",
    "    \n",
    "    # Keep only one date per unique week\n",
    "    unique_values = {}\n",
    "    for key, value in dataweeks.items():\n",
    "        if value not in unique_values.values():\n",
    "            unique_values[key] = value\n",
    "    keys_list = list(unique_values.keys())\n",
    "    filtered_dates = [hyear + '-' + date for date in keys_list]  # Restore to \"yyyy-mm-dd\" format\n",
    "    \n",
    "    Forecastyear = Forecastyears[region]    \n",
    "    # Ensure data is downloaded for the forecast year\n",
    "    for date in filtered_dates:\n",
    "        years = str(Forecastyear) + '_' + str(Forecastyear)\n",
    "        # Modify the study period here (startyear and endyear) if needed\n",
    "        hdates = '/'.join([f'{week}{date[4:]}' for week in range(endyear, endyear + 1)])\n",
    "        \n",
    "        # Download mx2t6 (maximum 2m temperature 6-hourly)\n",
    "        parameters = '121'\n",
    "        variable = 'mx2t6'\n",
    "        retrieve_mx2t6_mn2t6(date, parameters, variable, hdates, inputpath_base, origen, step1, num, region_limits, region, country, institution, years)\n",
    "        \n",
    "        # Download mn2t6 (minimum 2m temperature 6-hourly)\n",
    "        parameters = '122'\n",
    "        variable = 'mn2t6'\n",
    "        retrieve_mx2t6_mn2t6(date, parameters, variable, hdates, inputpath_base, origen, step1, num, region_limits, region, country, institution, years)\n",
    "        \n",
    "        # Download tp (total precipitation)\n",
    "        parameters = '228228'\n",
    "        variable = 'tp'\n",
    "        retrieve_tp_10_u_10v_ssr(date, parameters, variable, hdates, inputpath_base, origen, step2, num, region_limits, region, country, institution, years)\n",
    "        \n",
    "        # Download ssr (surface solar radiation)\n",
    "        parameters = '176'\n",
    "        variable = 'ssr'\n",
    "        retrieve_tp_10_u_10v_ssr(date, parameters, variable, hdates, inputpath_base, origen, step3, num, region_limits, region, country, institution, years)\n",
    "        \n",
    "        # Download 10u (10m zonal wind)\n",
    "        parameters = '165'\n",
    "        variable = '10u'\n",
    "        retrieve_tp_10_u_10v_ssr(date, parameters, variable, hdates, inputpath_base, origen, step3, num, region_limits, region, country, institution, years)\n",
    "        \n",
    "        # Download 10v (10m meridional wind)\n",
    "        parameters = '166'\n",
    "        variable = '10v'\n",
    "        retrieve_tp_10_u_10v_ssr(date, parameters, variable, hdates, inputpath_base, origen, step3, num, region_limits, region, country, institution, years)\n",
    "        \n",
    "        # Download 2d (2 metre dewpoint temperature)\n",
    "        parameters = '168'\n",
    "        variable = '2d'\n",
    "        retrieve_2d_2t(date, parameters, variable, hdates, inputpath_base, origen, step4, num, region_limits, region, country, institution, years)      \n",
    "        \n",
    "        # Download 2t (2 metre temperature)\n",
    "        parameters = '167'\n",
    "        variable = '2t'\n",
    "        retrieve_2d_2t(date, parameters, variable, hdates, inputpath_base, origen, step4, num, region_limits, region, country, institution, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6e3b7-7442-4dfd-87b5-c597547b744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When harvest_point is 46 (corresponding to December 27th), we can only go up to December 31st at most. Therefore, the last week is less than 8 days, with a maximum of 5 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632373ce-79c9-4fa3-8b9b-cda4f0715f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545de69b-26cc-4627-ae7e-e0761e4c165d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a358862-a904-44e3-8498-cba6738800a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d76528-85f6-4ee8-8c46-cef2989584dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a5f9e-5e88-4701-9284-4fe20e6263ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98397b-2a59-40f3-8740-b5562ef02d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab2aa6-4b2c-4f7a-9918-9c697c593408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e9305-4fd5-4aa3-9b2d-418bccdfac29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810fff4e-2e7b-492e-afea-2e39857e764d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba54bf-3d1a-4d80-a4ce-22e7e79b2aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8f157-38ae-4631-9f26-0e3c70f5118b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c59b1-571e-480e-abb0-79d97b3026ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8f5f2-e304-457e-b9cf-90a0792d091d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113d7a5-53e4-47a7-8a95-a04253eb2fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
